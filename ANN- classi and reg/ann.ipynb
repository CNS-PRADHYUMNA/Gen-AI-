{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04876f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder ,OneHotEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96df6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fb07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =load_data('data.csv')\n",
    "#drop unnecessary columns\n",
    "data= data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33284565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Geography_France  Geography_Germany  Geography_Spain\n",
      "0               1.0                0.0              0.0\n",
      "1               0.0                0.0              1.0\n",
      "2               1.0                0.0              0.0\n",
      "3               1.0                0.0              0.0\n",
      "4               0.0                0.0              1.0\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "lb= LabelEncoder()\n",
    "data['Gender'] = lb.fit_transform(data['Gender'])\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "ohe = OneHotEncoder()\n",
    "geo_encoder=ohe.fit_transform(data[['Geography']])\n",
    "\n",
    "ohe.get_feature_names_out(['Geography'])\n",
    "\n",
    "geo_df = pd.DataFrame(geo_encoder.toarray(), columns=ohe.get_feature_names_out(['Geography']))\n",
    "print(geo_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca3659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data.drop(['Geography'], axis=1), geo_df], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a93d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoders and scaler \n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(lb, f)\n",
    "with open('one_hot_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7749abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# save the scaler   \n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d4d61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 12), (2000, 12), (8000,), (2000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbe3682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Desktop\\git hosting\\Gen-ai\\Gen-AI\\ANN\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Desktop\\git hosting\\Gen-ai\\Gen-AI\\ANN\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ANN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Define the ANN model\n",
    "model= Sequential(\n",
    "    [\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a7cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3457 (13.50 KB)\n",
      "Trainable params: 3457 (13.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dcca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb48926",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=80,restore_best_weights=True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8397232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8649 - val_loss: 0.3485 - val_accuracy: 0.8570\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8659 - val_loss: 0.3382 - val_accuracy: 0.8650\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8669 - val_loss: 0.3431 - val_accuracy: 0.8580\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8683 - val_loss: 0.3431 - val_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8689 - val_loss: 0.3606 - val_accuracy: 0.8535\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8684 - val_loss: 0.3430 - val_accuracy: 0.8565\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8700 - val_loss: 0.3418 - val_accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8717 - val_loss: 0.3503 - val_accuracy: 0.8555\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8719 - val_loss: 0.3538 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8750 - val_loss: 0.3607 - val_accuracy: 0.8585\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8739 - val_loss: 0.3571 - val_accuracy: 0.8490\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8730 - val_loss: 0.3604 - val_accuracy: 0.8570\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8752 - val_loss: 0.3628 - val_accuracy: 0.8625\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8764 - val_loss: 0.3971 - val_accuracy: 0.8360\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8752 - val_loss: 0.3539 - val_accuracy: 0.8630\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8773 - val_loss: 0.3648 - val_accuracy: 0.8585\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8750 - val_loss: 0.3699 - val_accuracy: 0.8565\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8799 - val_loss: 0.3746 - val_accuracy: 0.8640\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8774 - val_loss: 0.3737 - val_accuracy: 0.8570\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.8800 - val_loss: 0.3606 - val_accuracy: 0.8585\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8769 - val_loss: 0.3869 - val_accuracy: 0.8550\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8809 - val_loss: 0.3652 - val_accuracy: 0.8635\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8831 - val_loss: 0.3694 - val_accuracy: 0.8600\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8804 - val_loss: 0.3878 - val_accuracy: 0.8585\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8856 - val_loss: 0.3897 - val_accuracy: 0.8565\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8835 - val_loss: 0.4240 - val_accuracy: 0.8585\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2746 - accuracy: 0.8829 - val_loss: 0.3966 - val_accuracy: 0.8530\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8848 - val_loss: 0.3925 - val_accuracy: 0.8535\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8875 - val_loss: 0.4037 - val_accuracy: 0.8560\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8869 - val_loss: 0.4081 - val_accuracy: 0.8575\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8869 - val_loss: 0.4066 - val_accuracy: 0.8540\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8867 - val_loss: 0.4184 - val_accuracy: 0.8540\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2654 - accuracy: 0.8850 - val_loss: 0.4239 - val_accuracy: 0.8555\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8844 - val_loss: 0.4105 - val_accuracy: 0.8585\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8879 - val_loss: 0.4204 - val_accuracy: 0.8580\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8881 - val_loss: 0.4228 - val_accuracy: 0.8585\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8860 - val_loss: 0.4345 - val_accuracy: 0.8525\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8920 - val_loss: 0.4755 - val_accuracy: 0.8570\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8886 - val_loss: 0.4763 - val_accuracy: 0.8550\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8898 - val_loss: 0.4822 - val_accuracy: 0.8520\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8891 - val_loss: 0.4168 - val_accuracy: 0.8570\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8903 - val_loss: 0.4503 - val_accuracy: 0.8465\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.8924 - val_loss: 0.4431 - val_accuracy: 0.8550\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8892 - val_loss: 0.4171 - val_accuracy: 0.8560\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.8914 - val_loss: 0.4567 - val_accuracy: 0.8520\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8914 - val_loss: 0.4725 - val_accuracy: 0.8515\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8931 - val_loss: 0.4624 - val_accuracy: 0.8515\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8944 - val_loss: 0.4572 - val_accuracy: 0.8515\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.8951 - val_loss: 0.5071 - val_accuracy: 0.8525\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.8960 - val_loss: 0.4678 - val_accuracy: 0.8470\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8939 - val_loss: 0.4681 - val_accuracy: 0.8430\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8953 - val_loss: 0.4594 - val_accuracy: 0.8510\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.8909 - val_loss: 0.4730 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.8951 - val_loss: 0.5039 - val_accuracy: 0.8505\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.8935 - val_loss: 0.5389 - val_accuracy: 0.8345\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.8932 - val_loss: 0.4965 - val_accuracy: 0.8490\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.8969 - val_loss: 0.5320 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.8946 - val_loss: 0.4805 - val_accuracy: 0.8450\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2284 - accuracy: 0.8959 - val_loss: 0.4941 - val_accuracy: 0.8470\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.8986 - val_loss: 0.5078 - val_accuracy: 0.8425\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.8946 - val_loss: 0.5036 - val_accuracy: 0.8545\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.8954 - val_loss: 0.5765 - val_accuracy: 0.8355\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.8982 - val_loss: 0.5036 - val_accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.8986 - val_loss: 0.5086 - val_accuracy: 0.8555\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.8995 - val_loss: 0.4934 - val_accuracy: 0.8515\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.8985 - val_loss: 0.4847 - val_accuracy: 0.8390\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.8970 - val_loss: 0.4997 - val_accuracy: 0.8530\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2283 - accuracy: 0.8976 - val_loss: 0.5929 - val_accuracy: 0.8480\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.8994 - val_loss: 0.5140 - val_accuracy: 0.8490\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9019 - val_loss: 0.5767 - val_accuracy: 0.8455\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.8978 - val_loss: 0.5366 - val_accuracy: 0.8530\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9003 - val_loss: 0.5163 - val_accuracy: 0.8455\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.8982 - val_loss: 0.6051 - val_accuracy: 0.8385\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9015 - val_loss: 0.5616 - val_accuracy: 0.8545\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2166 - accuracy: 0.9004 - val_loss: 0.5738 - val_accuracy: 0.8445\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.8985 - val_loss: 0.5114 - val_accuracy: 0.8405\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9022 - val_loss: 0.5587 - val_accuracy: 0.8465\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9006 - val_loss: 0.5365 - val_accuracy: 0.8475\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9019 - val_loss: 0.5692 - val_accuracy: 0.8410\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9024 - val_loss: 0.5138 - val_accuracy: 0.8415\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9038 - val_loss: 0.6193 - val_accuracy: 0.8510\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9035 - val_loss: 0.6012 - val_accuracy: 0.8420\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f84bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\OneDrive\\Desktop\\git hosting\\Gen-ai\\Gen-AI\\ANN\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model;\n",
    "model.save('ann_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cefa07ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#load the tensorflow\n",
    "\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c49e653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12980), started 0:00:43 ago. (Use '!kill 12980' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9b18771dd93fb9bf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9b18771dd93fb9bf\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4baf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pickle files and the model\n",
    "# with open('label_encoder.pkl', 'rb') as f:\n",
    "#     lb = pickle.load(f)\n",
    "# with open('one_hot_encoder.pkl', 'rb') as f:\n",
    "#     ohe = pickle.load(f)\n",
    "# with open('scaler.pkl', 'rb') as f:\n",
    "#     scaler = pickle.load(f)\n",
    "\n",
    "# using joblib to load the pickle files\n",
    "import joblib\n",
    "lb = joblib.load('label_encoder.pkl')\n",
    "ohe = joblib.load('one_hot_encoder.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "model= tf.keras.models.load_model('ann_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ed0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.05545291]]\n",
      "Prediction: Not Exited with probability 0.06\n"
     ]
    }
   ],
   "source": [
    "# sample  input\n",
    "input_data = {\n",
    "    'CreditScore': 600,\n",
    "    'Geography': 'France',\n",
    "    'Gender': 'Male',\n",
    "    'Age': 40,\n",
    "    'Tenure': 3,\n",
    "    'Balance': 60000,\n",
    "    'NumOfProducts': 2,\n",
    "    'HasCrCard': 1,\n",
    "    'IsActiveMember': 1,\n",
    "    'EstimatedSalary': 50000\n",
    "}\n",
    "\n",
    "input_data=pd.DataFrame([input_data])\n",
    "\n",
    "input_data['Gender'] = lb.transform(input_data['Gender'])\n",
    "\n",
    "geo_encoded = ohe.transform(input_data[['Geography']]).toarray()\n",
    "\n",
    "geo_df = pd.DataFrame(geo_encoded, columns=ohe.get_feature_names_out(['Geography']))\n",
    "input_data = pd.concat([input_data.drop(['Geography'], axis=1).reset_index(drop=True), geo_df], axis=1)\n",
    "\n",
    "input_data = scaler.transform(input_data)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "print(f\"Prediction: {'Exited' if prediction[0][0] > 0.5 else 'Not Exited'} with probability {prediction[0][0]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
